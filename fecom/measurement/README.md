# Energy Measurement Package

Please find further instructions for how to run the energy measurement program in the repository's top-level README.md file.
  
This package contains the following modules
- **cpu_temperature**: a wrapper around the `sensors` command from the `lm_sensors` library that records CPU temperatures at regular intervals
- **execution**: the key functions to measure energy consumption that are inserted before and after function calls into scripts by the patcher
- **idle_stats**: calculate statistics from steady state data to calculate experiment settings such as standard deviation to mean ratios that determine when the machine is in a steady state
- **measurement_config**: all constants and configuration values for energy measurements
- **measurement_parse**: functions to parse the measurement tool output files and load them into dataframes
- **stable_check**: perform stable check for energy and temperature, run before every energy measurement experiment.
- **start_measurement**: start the energy measurement scripts by running this module
- **utilities**: small utility functions

# JSON data
The execution script saves experimental data as JSON of the following format:  
```
function_to_run: {
        "energy_data": {
            "cpu": df_cpu_json,
            "ram": df_ram_json,
            "gpu": df_gpu_json
        },
        "times": {
            "start_time_execution": start_time_execution,
            "end_time_execution": end_time_execution,
            "start_time_perf": start_time_perf, 
            "end_time_perf": end_time_perf,
            "sys_start_time_perf": sys_start_time_perf,
            "start_time_nvidia": start_time_nvidia_normalised,
            "end_time_nvidia": end_time_nvidia_normalised,
            "sys_start_time_nvidia": sys_start_time_nvidia,
            "begin_stable_check_time": begin_stable_check_time,
            "begin_temperature_check_time": begin_temperature_check_time
        },
        "cpu_temperatures": cpu_temperatures,
        "settings" = {
            "max_wait_s": MAX_WAIT_S,
            "wait_after_run_s": WAIT_AFTER_RUN_S,
            "wait_per_stable_check_loop_s": WAIT_PER_STABLE_CHECK_LOOP_S,
            "tolerance": STABLE_CHECK_TOLERANCE,
            "measurement_interval_s": MEASUREMENT_INTERVAL_S,
            "cpu_std_to_mean": CPU_STD_TO_MEAN,
            "ram_std_to_mean": RAM_STD_TO_MEAN,
            "gpu_std_to_mean": GPU_STD_TO_MEAN,
            "check_last_n_points": CHECK_LAST_N_POINTS,
            "cpu_max_temp": CPU_MAXIMUM_TEMPERATURE,
            "gpu_max_temp": GPU_MAXIMUM_TEMPERATURE,
            "cpu_temperature_interval_s": CPU_TEMPERATURE_INTERVAL_S
        }
        "input_sizes" {
            "args_size": args_size_bit,
            "kwargs_size": kwargs_size_bit,
            "object_size": object_size_bit
        }
    }
```  
Where `function_to_run` is the full function signature.  

Each entry in `energy_data` is a Pandas DataFrame encoded as json through `pandas.DataFrame.to_json(orient='split')` which can be decoded into a DataFrame by calling `pd.read_json(df_json, orient=‘split’)`.  

The entries in `times` are start and end times measured in different ways. The `_execution` times are integers indicating time elapsed since epoch in nanoseconds and are the most accurate measure for start and end of execution. The `_perf` and `_nvidia` times are floats indicating time elapsed since start of energy measurement and are obtained by reading the most recent timestamp on the energy measurement data files generated by the `perf` and `nvidia-smi` tools, respectively. These are useful for aligning energy data with start/end times, in particular in combination with the `sys_` start times which give the tools' start times logged by `start_measurement.py` in time elapsed since epoch in nanoseconds. The other times indicate key times measured by the execution environment such as the begin of the stable and temperature check periods.  

The single value called `cpu_temperatures` is a DataFrame encoded as json (see `energy_data` above) that condains the cpu temperature readings over time collected during the temperature check period (before execution).  

The `settings` dictionary contains all relevant experiment settings. The capitalised values are constants defined in `measurement_config.py`. In theory, these settings can also be read by inspecting the config files, however, these might change between experiments to it can be useful to keep track of the settings in a more permanent way. This can be used to confirm that settings were kept the same across experiments.

Each entry in `input_sizes` is an integer indicating the approximate size of each input variable in bit. This approximation is obtained by calling `len(pickle.dumps(input_variable))`, i.e. by determining the length of a bitestring generated by serialising the `input_variable` using the built-in `pickle` library.