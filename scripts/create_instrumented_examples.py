#!/usr/bin/env python3
"""
Create instrumented code examples for all languages
"""

import sys
import os
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from src.instrumentation.language_engine import LanguageEngine

def create_instrumented_example(language, input_file, output_file):
    """Create an instrumented version of a source file"""
    print(f"\nüîß Creating instrumented {language} example...")
    print(f"   Input: {input_file}")
    print(f"   Output: {output_file}")
    
    # Read source code
    if not os.path.exists(input_file):
        print(f"‚ùå Input file does not exist: {input_file}")
        return False
    
    with open(input_file, 'r') as f:
        source_code = f.read()
    
    # Analyze and get instrumentation points
    engine = LanguageEngine()
    result = engine.analyze_code(source_code, language=language, filename=input_file)
    
    if not result.success:
        print(f"‚ùå Analysis failed: {result.error}")
        return False
    
    print(f"   ‚úì Found {len(result.instrumentation_points)} instrumentation points")
    
    # For now, just copy the original file and add a comment about instrumentation points
    # In a real implementation, you'd use the AST processor to insert the actual checkpoints
    
    instrumented_content = f"""# INSTRUMENTED VERSION - Generated by CodeGreen
# Original file: {input_file}
# Language: {language}
# Instrumentation points found: {len(result.instrumentation_points)}
#
# Instrumentation Summary:
"""
    
    # Group points by type
    by_type = {}
    for point in result.instrumentation_points:
        point_type = point.type
        if point_type not in by_type:
            by_type[point_type] = []
        by_type[point_type].append(point)
    
    for point_type, points in by_type.items():
        instrumented_content += f"# - {point_type}: {len(points)} points\n"
        for point in points:
            instrumented_content += f"#   * {point.id} at line {point.line} ({point.name})\n"
    
    instrumented_content += "#\n# NOTE: This is a summary. Actual instrumentation would insert\n"
    instrumented_content += "# runtime checkpoints at the specified locations.\n\n"
    
    # Add original content with line numbers for reference
    lines = source_code.split('\n')
    for i, line in enumerate(lines, 1):
        instrumented_content += f"{line}\n"
    
    # Write instrumented version
    with open(output_file, 'w') as f:
        f.write(instrumented_content)
    
    print(f"   ‚úÖ Successfully created instrumented example: {output_file}")
    return True

def main():
    examples = [
        ('python', 'examples/python_sample.py', 'examples/python_sample_instrumented.py'),
        ('cpp', 'examples/cpp_sample.cpp', 'examples/cpp_sample_instrumented.cpp'),
        ('c', 'examples/c_sample.c', 'examples/c_sample_instrumented.c'),
        ('java', 'examples/JavaSample.java', 'examples/JavaSample_instrumented.java'),
        ('python', 'examples/simple_test.py', 'examples/simple_test_instrumented.py'),
    ]
    
    print("üöÄ Creating instrumented code examples for all languages...")
    print("=" * 70)
    
    success_count = 0
    total_count = len(examples)
    
    for language, input_file, output_file in examples:
        success = create_instrumented_example(language, input_file, output_file)
        if success:
            success_count += 1
        print("-" * 40)
    
    print(f"\nüìä Results: {success_count}/{total_count} instrumented examples created")
    
    if success_count == total_count:
        print("üéâ All instrumented examples created successfully!")
        return True
    else:
        print(f"‚ö†Ô∏è  {total_count - success_count} examples failed")
        return False

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)